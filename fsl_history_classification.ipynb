{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 各パス指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'model/fsl_words_classifier/fsl_words.csv'\n",
    "model_save_path = 'model/fsl_words_classifier/fsl_words_classifier.keras'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分類数設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 入力長"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_STEPS = 16\n",
    "DIMENSION = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dataset = np.loadtxt(dataset, delimiter=',', dtype='float32', usecols=list(range(1, (TIME_STEPS * DIMENSION) + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dataset = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, train_size=0.75, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_lstm = True\n",
    "model = None\n",
    "\n",
    "if use_lstm:\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(TIME_STEPS * DIMENSION, )),\n",
    "        tf.keras.layers.Reshape((TIME_STEPS, DIMENSION), input_shape=(TIME_STEPS * DIMENSION, )), \n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.LSTM(16, input_shape=[TIME_STEPS, DIMENSION]),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(10, activation='relu'),\n",
    "        tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "    ])\n",
    "else:\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(TIME_STEPS * DIMENSION, )),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(24, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(10, activation='relu'),\n",
    "        tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ reshape_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,216</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ reshape_2 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m2\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m2\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m1,216\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m170\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m22\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,408</span> (5.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,408\u001b[0m (5.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,408</span> (5.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,408\u001b[0m (5.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()  # tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルチェックポイントのコールバック\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    model_save_path, verbose=1, save_weights_only=False)\n",
    "# 早期打ち切り用コールバック\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルコンパイル\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.4375 - loss: 0.7096\n",
      "Epoch 1: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 279ms/step - accuracy: 0.4572 - loss: 0.7047 - val_accuracy: 0.4839 - val_loss: 0.6988\n",
      "Epoch 2/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.5703 - loss: 0.6885\n",
      "Epoch 2: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.5755 - loss: 0.6870 - val_accuracy: 0.6290 - val_loss: 0.6871\n",
      "Epoch 3/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6719 - loss: 0.6869\n",
      "Epoch 3: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.6935 - loss: 0.6782 - val_accuracy: 0.7339 - val_loss: 0.6749\n",
      "Epoch 4/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.7578 - loss: 0.6588\n",
      "Epoch 4: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7554 - loss: 0.6600 - val_accuracy: 0.7339 - val_loss: 0.6624\n",
      "Epoch 5/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7578 - loss: 0.6529\n",
      "Epoch 5: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.7737 - loss: 0.6488 - val_accuracy: 0.7339 - val_loss: 0.6501\n",
      "Epoch 6/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7969 - loss: 0.6324\n",
      "Epoch 6: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.7894 - loss: 0.6326 - val_accuracy: 0.7339 - val_loss: 0.6377\n",
      "Epoch 7/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.7422 - loss: 0.6397\n",
      "Epoch 7: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7738 - loss: 0.6263 - val_accuracy: 0.7339 - val_loss: 0.6253\n",
      "Epoch 8/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7812 - loss: 0.6029\n",
      "Epoch 8: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7842 - loss: 0.6037 - val_accuracy: 0.7339 - val_loss: 0.6131\n",
      "Epoch 9/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7578 - loss: 0.5961\n",
      "Epoch 9: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7806 - loss: 0.5907 - val_accuracy: 0.7339 - val_loss: 0.6010\n",
      "Epoch 10/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.7500 - loss: 0.5916\n",
      "Epoch 10: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7728 - loss: 0.5778 - val_accuracy: 0.7339 - val_loss: 0.5892\n",
      "Epoch 11/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7500 - loss: 0.5785\n",
      "Epoch 11: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7767 - loss: 0.5657 - val_accuracy: 0.7339 - val_loss: 0.5777\n",
      "Epoch 12/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7812 - loss: 0.5578\n",
      "Epoch 12: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7885 - loss: 0.5484 - val_accuracy: 0.7339 - val_loss: 0.5667\n",
      "Epoch 13/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7422 - loss: 0.5539\n",
      "Epoch 13: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.7699 - loss: 0.5382 - val_accuracy: 0.7339 - val_loss: 0.5567\n",
      "Epoch 14/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8125 - loss: 0.5134\n",
      "Epoch 14: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.7953 - loss: 0.5189 - val_accuracy: 0.7339 - val_loss: 0.5477\n",
      "Epoch 15/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7812 - loss: 0.5243\n",
      "Epoch 15: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7865 - loss: 0.5145 - val_accuracy: 0.7339 - val_loss: 0.5412\n",
      "Epoch 16/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7734 - loss: 0.4999\n",
      "Epoch 16: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.7826 - loss: 0.4950 - val_accuracy: 0.7339 - val_loss: 0.5373\n",
      "Epoch 17/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7500 - loss: 0.5236\n",
      "Epoch 17: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.7767 - loss: 0.5000 - val_accuracy: 0.7339 - val_loss: 0.5352\n",
      "Epoch 18/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7734 - loss: 0.4960\n",
      "Epoch 18: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.7826 - loss: 0.4910 - val_accuracy: 0.7339 - val_loss: 0.5325\n",
      "Epoch 19/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7812 - loss: 0.4969\n",
      "Epoch 19: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.7806 - loss: 0.5002 - val_accuracy: 0.7339 - val_loss: 0.5282\n",
      "Epoch 20/1000\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.7852 - loss: 0.4903\n",
      "Epoch 20: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 241ms/step - accuracy: 0.7869 - loss: 0.4829 - val_accuracy: 0.7339 - val_loss: 0.5208\n",
      "Epoch 21/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7891 - loss: 0.4547\n",
      "Epoch 21: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.7865 - loss: 0.4659 - val_accuracy: 0.7339 - val_loss: 0.5126\n",
      "Epoch 22/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7812 - loss: 0.4602\n",
      "Epoch 22: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7816 - loss: 0.4605 - val_accuracy: 0.7339 - val_loss: 0.5046\n",
      "Epoch 23/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7266 - loss: 0.5076\n",
      "Epoch 23: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.7722 - loss: 0.4708 - val_accuracy: 0.7419 - val_loss: 0.4973\n",
      "Epoch 24/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.7188 - loss: 0.5114\n",
      "Epoch 24: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.7664 - loss: 0.4697 - val_accuracy: 0.7419 - val_loss: 0.4899\n",
      "Epoch 25/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.8047 - loss: 0.4231\n",
      "Epoch 25: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.7902 - loss: 0.4426 - val_accuracy: 0.7419 - val_loss: 0.4833\n",
      "Epoch 26/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.8359 - loss: 0.4101\n",
      "Epoch 26: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.8012 - loss: 0.4318 - val_accuracy: 0.7500 - val_loss: 0.4776\n",
      "Epoch 27/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7891 - loss: 0.4376\n",
      "Epoch 27: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7898 - loss: 0.4289 - val_accuracy: 0.7500 - val_loss: 0.4714\n",
      "Epoch 28/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.7734 - loss: 0.4394\n",
      "Epoch 28: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7797 - loss: 0.4391 - val_accuracy: 0.7500 - val_loss: 0.4649\n",
      "Epoch 29/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7734 - loss: 0.4543\n",
      "Epoch 29: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7976 - loss: 0.4305 - val_accuracy: 0.7500 - val_loss: 0.4583\n",
      "Epoch 30/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8203 - loss: 0.3898\n",
      "Epoch 30: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8052 - loss: 0.4110 - val_accuracy: 0.7500 - val_loss: 0.4516\n",
      "Epoch 31/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7656 - loss: 0.4516\n",
      "Epoch 31: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7950 - loss: 0.4234 - val_accuracy: 0.7500 - val_loss: 0.4451\n",
      "Epoch 32/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.8516 - loss: 0.3737\n",
      "Epoch 32: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.8078 - loss: 0.3991 - val_accuracy: 0.7500 - val_loss: 0.4406\n",
      "Epoch 33/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7891 - loss: 0.4088\n",
      "Epoch 33: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.8019 - loss: 0.3998 - val_accuracy: 0.7581 - val_loss: 0.4369\n",
      "Epoch 34/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7734 - loss: 0.4139\n",
      "Epoch 34: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.7878 - loss: 0.4136 - val_accuracy: 0.7661 - val_loss: 0.4321\n",
      "Epoch 35/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.8125 - loss: 0.4037\n",
      "Epoch 35: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.8100 - loss: 0.4042 - val_accuracy: 0.7742 - val_loss: 0.4268\n",
      "Epoch 36/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8281 - loss: 0.3780\n",
      "Epoch 36: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.8163 - loss: 0.3962 - val_accuracy: 0.7823 - val_loss: 0.4184\n",
      "Epoch 37/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.8281 - loss: 0.3767\n",
      "Epoch 37: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.8186 - loss: 0.3798 - val_accuracy: 0.7984 - val_loss: 0.4117\n",
      "Epoch 38/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.7891 - loss: 0.4366\n",
      "Epoch 38: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.8034 - loss: 0.3952 - val_accuracy: 0.7984 - val_loss: 0.4045\n",
      "Epoch 39/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.7812 - loss: 0.4218\n",
      "Epoch 39: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8063 - loss: 0.3945 - val_accuracy: 0.8065 - val_loss: 0.3983\n",
      "Epoch 40/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8594 - loss: 0.3409\n",
      "Epoch 40: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.8254 - loss: 0.3628 - val_accuracy: 0.8145 - val_loss: 0.3932\n",
      "Epoch 41/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.7891 - loss: 0.3930\n",
      "Epoch 41: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.8043 - loss: 0.3823 - val_accuracy: 0.8065 - val_loss: 0.3882\n",
      "Epoch 42/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.8281 - loss: 0.3435\n",
      "Epoch 42: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.8227 - loss: 0.3542 - val_accuracy: 0.8226 - val_loss: 0.3859\n",
      "Epoch 43/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7812 - loss: 0.3910\n",
      "Epoch 43: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.8032 - loss: 0.3617 - val_accuracy: 0.8226 - val_loss: 0.3833\n",
      "Epoch 44/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.7969 - loss: 0.3831\n",
      "Epoch 44: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.8222 - loss: 0.3660 - val_accuracy: 0.8306 - val_loss: 0.3795\n",
      "Epoch 45/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.8125 - loss: 0.3504\n",
      "Epoch 45: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.8054 - loss: 0.3593 - val_accuracy: 0.8226 - val_loss: 0.3746\n",
      "Epoch 46/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7891 - loss: 0.4002\n",
      "Epoch 46: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.8046 - loss: 0.3664 - val_accuracy: 0.8387 - val_loss: 0.3668\n",
      "Epoch 47/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8594 - loss: 0.3276\n",
      "Epoch 47: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.8288 - loss: 0.3425 - val_accuracy: 0.8468 - val_loss: 0.3621\n",
      "Epoch 48/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7500 - loss: 0.3972\n",
      "Epoch 48: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.7862 - loss: 0.3649 - val_accuracy: 0.8306 - val_loss: 0.3591\n",
      "Epoch 49/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8672 - loss: 0.3184\n",
      "Epoch 49: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.8197 - loss: 0.3386 - val_accuracy: 0.8468 - val_loss: 0.3550\n",
      "Epoch 50/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8281 - loss: 0.3474\n",
      "Epoch 50: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.8310 - loss: 0.3415 - val_accuracy: 0.8387 - val_loss: 0.3504\n",
      "Epoch 51/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.8438 - loss: 0.3405\n",
      "Epoch 51: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.8416 - loss: 0.3348 - val_accuracy: 0.8387 - val_loss: 0.3474\n",
      "Epoch 52/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.8672 - loss: 0.2892\n",
      "Epoch 52: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.8400 - loss: 0.3123 - val_accuracy: 0.8306 - val_loss: 0.3471\n",
      "Epoch 53/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7891 - loss: 0.3636\n",
      "Epoch 53: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.8174 - loss: 0.3424 - val_accuracy: 0.8387 - val_loss: 0.3428\n",
      "Epoch 54/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.8203 - loss: 0.3419\n",
      "Epoch 54: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.8267 - loss: 0.3316 - val_accuracy: 0.8387 - val_loss: 0.3362\n",
      "Epoch 55/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8359 - loss: 0.3223\n",
      "Epoch 55: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.8326 - loss: 0.3213 - val_accuracy: 0.8710 - val_loss: 0.3297\n",
      "Epoch 56/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8359 - loss: 0.3170\n",
      "Epoch 56: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.8454 - loss: 0.3081 - val_accuracy: 0.8871 - val_loss: 0.3252\n",
      "Epoch 57/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8594 - loss: 0.2951\n",
      "Epoch 57: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.8507 - loss: 0.3151 - val_accuracy: 0.8790 - val_loss: 0.3226\n",
      "Epoch 58/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8672 - loss: 0.2874\n",
      "Epoch 58: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.8538 - loss: 0.2984 - val_accuracy: 0.8710 - val_loss: 0.3137\n",
      "Epoch 59/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8516 - loss: 0.3041\n",
      "Epoch 59: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.8686 - loss: 0.2959 - val_accuracy: 0.8871 - val_loss: 0.3033\n",
      "Epoch 60/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8594 - loss: 0.2941\n",
      "Epoch 60: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8662 - loss: 0.2958 - val_accuracy: 0.8952 - val_loss: 0.2927\n",
      "Epoch 61/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8203 - loss: 0.3242\n",
      "Epoch 61: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.8646 - loss: 0.3018 - val_accuracy: 0.8952 - val_loss: 0.2847\n",
      "Epoch 62/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.8828 - loss: 0.2974\n",
      "Epoch 62: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.8870 - loss: 0.2847 - val_accuracy: 0.8952 - val_loss: 0.2779\n",
      "Epoch 63/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8750 - loss: 0.2479\n",
      "Epoch 63: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.8731 - loss: 0.2651 - val_accuracy: 0.8952 - val_loss: 0.2747\n",
      "Epoch 64/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8750 - loss: 0.3150\n",
      "Epoch 64: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.8707 - loss: 0.2959 - val_accuracy: 0.9032 - val_loss: 0.2645\n",
      "Epoch 65/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9219 - loss: 0.2448\n",
      "Epoch 65: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.8993 - loss: 0.2609 - val_accuracy: 0.9113 - val_loss: 0.2547\n",
      "Epoch 66/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8594 - loss: 0.3252\n",
      "Epoch 66: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.8829 - loss: 0.2848 - val_accuracy: 0.9355 - val_loss: 0.2447\n",
      "Epoch 67/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9297 - loss: 0.2565\n",
      "Epoch 67: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.9141 - loss: 0.2567 - val_accuracy: 0.9355 - val_loss: 0.2368\n",
      "Epoch 68/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.9453 - loss: 0.2215\n",
      "Epoch 68: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.9180 - loss: 0.2413 - val_accuracy: 0.9274 - val_loss: 0.2331\n",
      "Epoch 69/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9219 - loss: 0.2322\n",
      "Epoch 69: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.9011 - loss: 0.2592 - val_accuracy: 0.9355 - val_loss: 0.2287\n",
      "Epoch 70/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9219 - loss: 0.2179\n",
      "Epoch 70: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.8939 - loss: 0.2458 - val_accuracy: 0.9355 - val_loss: 0.2216\n",
      "Epoch 71/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8984 - loss: 0.2293\n",
      "Epoch 71: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.8991 - loss: 0.2328 - val_accuracy: 0.9274 - val_loss: 0.2184\n",
      "Epoch 72/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8828 - loss: 0.2963\n",
      "Epoch 72: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.8932 - loss: 0.2694 - val_accuracy: 0.9355 - val_loss: 0.2096\n",
      "Epoch 73/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9062 - loss: 0.2257\n",
      "Epoch 73: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.9057 - loss: 0.2284 - val_accuracy: 0.9435 - val_loss: 0.2050\n",
      "Epoch 74/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8750 - loss: 0.2251\n",
      "Epoch 74: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.8837 - loss: 0.2339 - val_accuracy: 0.9435 - val_loss: 0.2000\n",
      "Epoch 75/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.8828 - loss: 0.2438\n",
      "Epoch 75: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8901 - loss: 0.2496 - val_accuracy: 0.9435 - val_loss: 0.1958\n",
      "Epoch 76/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9453 - loss: 0.1920\n",
      "Epoch 76: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9205 - loss: 0.2206 - val_accuracy: 0.9516 - val_loss: 0.1929\n",
      "Epoch 77/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9219 - loss: 0.2450\n",
      "Epoch 77: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9065 - loss: 0.2394 - val_accuracy: 0.9516 - val_loss: 0.1881\n",
      "Epoch 78/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9219 - loss: 0.1807\n",
      "Epoch 78: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9013 - loss: 0.2226 - val_accuracy: 0.9435 - val_loss: 0.1845\n",
      "Epoch 79/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8984 - loss: 0.2498\n",
      "Epoch 79: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8958 - loss: 0.2423 - val_accuracy: 0.9435 - val_loss: 0.1832\n",
      "Epoch 80/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8828 - loss: 0.2582\n",
      "Epoch 80: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8975 - loss: 0.2498 - val_accuracy: 0.9435 - val_loss: 0.1822\n",
      "Epoch 81/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8828 - loss: 0.2293\n",
      "Epoch 81: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.8944 - loss: 0.2241 - val_accuracy: 0.9435 - val_loss: 0.1819\n",
      "Epoch 82/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8828 - loss: 0.2239\n",
      "Epoch 82: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.8759 - loss: 0.2268 - val_accuracy: 0.9435 - val_loss: 0.1834\n",
      "Epoch 83/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8906 - loss: 0.2203\n",
      "Epoch 83: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.8952 - loss: 0.2240 - val_accuracy: 0.9435 - val_loss: 0.1820\n",
      "Epoch 84/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9062 - loss: 0.1932\n",
      "Epoch 84: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8970 - loss: 0.2067 - val_accuracy: 0.9435 - val_loss: 0.1812\n",
      "Epoch 85/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8438 - loss: 0.2834\n",
      "Epoch 85: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8780 - loss: 0.2443 - val_accuracy: 0.9355 - val_loss: 0.1846\n",
      "Epoch 86/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8828 - loss: 0.2292\n",
      "Epoch 86: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8952 - loss: 0.2244 - val_accuracy: 0.9355 - val_loss: 0.1816\n",
      "Epoch 87/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9062 - loss: 0.1812\n",
      "Epoch 87: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9040 - loss: 0.2028 - val_accuracy: 0.9435 - val_loss: 0.1761\n",
      "Epoch 88/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8984 - loss: 0.2038\n",
      "Epoch 88: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.9045 - loss: 0.2084 - val_accuracy: 0.9435 - val_loss: 0.1699\n",
      "Epoch 89/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8984 - loss: 0.2403\n",
      "Epoch 89: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9072 - loss: 0.2239 - val_accuracy: 0.9516 - val_loss: 0.1656\n",
      "Epoch 90/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9219 - loss: 0.2288\n",
      "Epoch 90: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.9162 - loss: 0.2204 - val_accuracy: 0.9516 - val_loss: 0.1646\n",
      "Epoch 91/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8906 - loss: 0.2373\n",
      "Epoch 91: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9031 - loss: 0.2401 - val_accuracy: 0.9435 - val_loss: 0.1592\n",
      "Epoch 92/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8984 - loss: 0.2057\n",
      "Epoch 92: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.8950 - loss: 0.2114 - val_accuracy: 0.9435 - val_loss: 0.1581\n",
      "Epoch 93/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.9141 - loss: 0.2261\n",
      "Epoch 93: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.9077 - loss: 0.2191 - val_accuracy: 0.9435 - val_loss: 0.1576\n",
      "Epoch 94/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.9453 - loss: 0.1937\n",
      "Epoch 94: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.9172 - loss: 0.2087 - val_accuracy: 0.9435 - val_loss: 0.1577\n",
      "Epoch 95/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.9062 - loss: 0.1934\n",
      "Epoch 95: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.9090 - loss: 0.2018 - val_accuracy: 0.9516 - val_loss: 0.1634\n",
      "Epoch 96/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.9062 - loss: 0.2155\n",
      "Epoch 96: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.9135 - loss: 0.2024 - val_accuracy: 0.9516 - val_loss: 0.1608\n",
      "Epoch 97/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.9297 - loss: 0.1836\n",
      "Epoch 97: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.9192 - loss: 0.1862 - val_accuracy: 0.9435 - val_loss: 0.1571\n",
      "Epoch 98/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9688 - loss: 0.2052\n",
      "Epoch 98: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.9390 - loss: 0.1952 - val_accuracy: 0.9435 - val_loss: 0.1537\n",
      "Epoch 99/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 0.9375 - loss: 0.1821\n",
      "Epoch 99: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9298 - loss: 0.1997 - val_accuracy: 0.9435 - val_loss: 0.1500\n",
      "Epoch 100/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8828 - loss: 0.2291\n",
      "Epoch 100: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.8975 - loss: 0.2109 - val_accuracy: 0.9435 - val_loss: 0.1487\n",
      "Epoch 101/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9297 - loss: 0.1649\n",
      "Epoch 101: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9225 - loss: 0.1794 - val_accuracy: 0.9435 - val_loss: 0.1474\n",
      "Epoch 102/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9297 - loss: 0.1754\n",
      "Epoch 102: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.9071 - loss: 0.1910 - val_accuracy: 0.9435 - val_loss: 0.1437\n",
      "Epoch 103/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.9297 - loss: 0.1655\n",
      "Epoch 103: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9253 - loss: 0.1829 - val_accuracy: 0.9516 - val_loss: 0.1426\n",
      "Epoch 104/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.9141 - loss: 0.1856\n",
      "Epoch 104: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9063 - loss: 0.2082 - val_accuracy: 0.9435 - val_loss: 0.1502\n",
      "Epoch 105/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9297 - loss: 0.1803\n",
      "Epoch 105: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.9240 - loss: 0.2038 - val_accuracy: 0.9597 - val_loss: 0.1442\n",
      "Epoch 106/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8906 - loss: 0.2216\n",
      "Epoch 106: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.9105 - loss: 0.2007 - val_accuracy: 0.9435 - val_loss: 0.1382\n",
      "Epoch 107/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8984 - loss: 0.2166\n",
      "Epoch 107: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.9135 - loss: 0.2008 - val_accuracy: 0.9435 - val_loss: 0.1364\n",
      "Epoch 108/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.9375 - loss: 0.1706\n",
      "Epoch 108: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.9182 - loss: 0.1857 - val_accuracy: 0.9435 - val_loss: 0.1354\n",
      "Epoch 109/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9375 - loss: 0.1914\n",
      "Epoch 109: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9316 - loss: 0.1961 - val_accuracy: 0.9597 - val_loss: 0.1371\n",
      "Epoch 110/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9375 - loss: 0.1735\n",
      "Epoch 110: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9298 - loss: 0.1804 - val_accuracy: 0.9597 - val_loss: 0.1399\n",
      "Epoch 111/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9297 - loss: 0.1715\n",
      "Epoch 111: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9333 - loss: 0.1719 - val_accuracy: 0.9597 - val_loss: 0.1391\n",
      "Epoch 112/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9141 - loss: 0.1773\n",
      "Epoch 112: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9244 - loss: 0.1720 - val_accuracy: 0.9597 - val_loss: 0.1375\n",
      "Epoch 113/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9219 - loss: 0.1905\n",
      "Epoch 113: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9310 - loss: 0.1748 - val_accuracy: 0.9597 - val_loss: 0.1366\n",
      "Epoch 114/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8984 - loss: 0.2186\n",
      "Epoch 114: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9119 - loss: 0.1843 - val_accuracy: 0.9597 - val_loss: 0.1355\n",
      "Epoch 115/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9141 - loss: 0.1864\n",
      "Epoch 115: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.9177 - loss: 0.1887 - val_accuracy: 0.9516 - val_loss: 0.1334\n",
      "Epoch 116/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9141 - loss: 0.2176\n",
      "Epoch 116: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9137 - loss: 0.2078 - val_accuracy: 0.9597 - val_loss: 0.1302\n",
      "Epoch 117/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9297 - loss: 0.1667\n",
      "Epoch 117: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9323 - loss: 0.1720 - val_accuracy: 0.9516 - val_loss: 0.1269\n",
      "Epoch 118/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9375 - loss: 0.1861\n",
      "Epoch 118: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9316 - loss: 0.1833 - val_accuracy: 0.9435 - val_loss: 0.1244\n",
      "Epoch 119/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 0.9297 - loss: 0.1402\n",
      "Epoch 119: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.9189 - loss: 0.1676 - val_accuracy: 0.9516 - val_loss: 0.1232\n",
      "Epoch 120/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.9219 - loss: 0.1707\n",
      "Epoch 120: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9154 - loss: 0.1879 - val_accuracy: 0.9597 - val_loss: 0.1228\n",
      "Epoch 121/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9219 - loss: 0.1675\n",
      "Epoch 121: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.9149 - loss: 0.1683 - val_accuracy: 0.9597 - val_loss: 0.1218\n",
      "Epoch 122/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9453 - loss: 0.1601\n",
      "Epoch 122: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9337 - loss: 0.1729 - val_accuracy: 0.9597 - val_loss: 0.1215\n",
      "Epoch 123/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9609 - loss: 0.1614\n",
      "Epoch 123: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.9431 - loss: 0.1714 - val_accuracy: 0.9597 - val_loss: 0.1211\n",
      "Epoch 124/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9141 - loss: 0.1735\n",
      "Epoch 124: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9177 - loss: 0.1761 - val_accuracy: 0.9677 - val_loss: 0.1207\n",
      "Epoch 125/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9454 - loss: 0.1600\n",
      "Epoch 125: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9434 - loss: 0.1589 - val_accuracy: 0.9597 - val_loss: 0.1202\n",
      "Epoch 126/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9219 - loss: 0.1883\n",
      "Epoch 126: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9307 - loss: 0.1738 - val_accuracy: 0.9677 - val_loss: 0.1195\n",
      "Epoch 127/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9297 - loss: 0.1723\n",
      "Epoch 127: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9279 - loss: 0.1686 - val_accuracy: 0.9677 - val_loss: 0.1195\n",
      "Epoch 128/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9609 - loss: 0.1271\n",
      "Epoch 128: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9428 - loss: 0.1509 - val_accuracy: 0.9677 - val_loss: 0.1195\n",
      "Epoch 129/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9531 - loss: 0.1251\n",
      "Epoch 129: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.9411 - loss: 0.1504 - val_accuracy: 0.9677 - val_loss: 0.1198\n",
      "Epoch 130/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.9297 - loss: 0.1590\n",
      "Epoch 130: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9226 - loss: 0.1657 - val_accuracy: 0.9677 - val_loss: 0.1187\n",
      "Epoch 131/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9688 - loss: 0.1115\n",
      "Epoch 131: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9437 - loss: 0.1455 - val_accuracy: 0.9677 - val_loss: 0.1169\n",
      "Epoch 132/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9688 - loss: 0.1095\n",
      "Epoch 132: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9491 - loss: 0.1421 - val_accuracy: 0.9677 - val_loss: 0.1164\n",
      "Epoch 133/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9453 - loss: 0.1364\n",
      "Epoch 133: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9359 - loss: 0.1566 - val_accuracy: 0.9597 - val_loss: 0.1164\n",
      "Epoch 134/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9219 - loss: 0.1723\n",
      "Epoch 134: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.9143 - loss: 0.1802 - val_accuracy: 0.9597 - val_loss: 0.1166\n",
      "Epoch 135/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9219 - loss: 0.2072\n",
      "Epoch 135: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.9164 - loss: 0.1926 - val_accuracy: 0.9677 - val_loss: 0.1164\n",
      "Epoch 136/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9531 - loss: 0.1455\n",
      "Epoch 136: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9318 - loss: 0.1788 - val_accuracy: 0.9677 - val_loss: 0.1146\n",
      "Epoch 137/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9141 - loss: 0.1867\n",
      "Epoch 137: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9224 - loss: 0.1818 - val_accuracy: 0.9677 - val_loss: 0.1131\n",
      "Epoch 138/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9062 - loss: 0.1963\n",
      "Epoch 138: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9257 - loss: 0.1804 - val_accuracy: 0.9677 - val_loss: 0.1132\n",
      "Epoch 139/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9375 - loss: 0.1448\n",
      "Epoch 139: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9353 - loss: 0.1509 - val_accuracy: 0.9677 - val_loss: 0.1153\n",
      "Epoch 140/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9062 - loss: 0.2523\n",
      "Epoch 140: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9288 - loss: 0.2163 - val_accuracy: 0.9677 - val_loss: 0.1100\n",
      "Epoch 141/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9688 - loss: 0.1210\n",
      "Epoch 141: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9423 - loss: 0.1576 - val_accuracy: 0.9677 - val_loss: 0.1076\n",
      "Epoch 142/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9219 - loss: 0.1837\n",
      "Epoch 142: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.9180 - loss: 0.1899 - val_accuracy: 0.9677 - val_loss: 0.1066\n",
      "Epoch 143/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9453 - loss: 0.1551\n",
      "Epoch 143: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9345 - loss: 0.1601 - val_accuracy: 0.9677 - val_loss: 0.1062\n",
      "Epoch 144/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9453 - loss: 0.1787\n",
      "Epoch 144: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.9411 - loss: 0.1611 - val_accuracy: 0.9677 - val_loss: 0.1064\n",
      "Epoch 145/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9297 - loss: 0.1831\n",
      "Epoch 145: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9386 - loss: 0.1591 - val_accuracy: 0.9597 - val_loss: 0.1068\n",
      "Epoch 146/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9453 - loss: 0.1499\n",
      "Epoch 146: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9380 - loss: 0.1614 - val_accuracy: 0.9677 - val_loss: 0.1070\n",
      "Epoch 147/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.8906 - loss: 0.2028\n",
      "Epoch 147: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.9239 - loss: 0.1607 - val_accuracy: 0.9677 - val_loss: 0.1086\n",
      "Epoch 148/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9219 - loss: 0.2002\n",
      "Epoch 148: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.9224 - loss: 0.1848 - val_accuracy: 0.9677 - val_loss: 0.1087\n",
      "Epoch 149/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9375 - loss: 0.1532\n",
      "Epoch 149: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9318 - loss: 0.1658 - val_accuracy: 0.9597 - val_loss: 0.1085\n",
      "Epoch 150/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9453 - loss: 0.1618\n",
      "Epoch 150: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.9341 - loss: 0.1573 - val_accuracy: 0.9597 - val_loss: 0.1094\n",
      "Epoch 151/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9062 - loss: 0.2539\n",
      "Epoch 151: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9181 - loss: 0.2081 - val_accuracy: 0.9677 - val_loss: 0.1083\n",
      "Epoch 152/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - accuracy: 0.9375 - loss: 0.1819\n",
      "Epoch 152: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9255 - loss: 0.1751 - val_accuracy: 0.9677 - val_loss: 0.1042\n",
      "Epoch 153/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8984 - loss: 0.1902\n",
      "Epoch 153: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9175 - loss: 0.1754 - val_accuracy: 0.9677 - val_loss: 0.1011\n",
      "Epoch 154/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9375 - loss: 0.1665\n",
      "Epoch 154: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9362 - loss: 0.1684 - val_accuracy: 0.9677 - val_loss: 0.0990\n",
      "Epoch 155/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9219 - loss: 0.1631\n",
      "Epoch 155: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9166 - loss: 0.1688 - val_accuracy: 0.9677 - val_loss: 0.0975\n",
      "Epoch 156/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9531 - loss: 0.1176\n",
      "Epoch 156: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9378 - loss: 0.1496 - val_accuracy: 0.9677 - val_loss: 0.0969\n",
      "Epoch 157/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9141 - loss: 0.1950\n",
      "Epoch 157: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.9261 - loss: 0.1847 - val_accuracy: 0.9677 - val_loss: 0.0978\n",
      "Epoch 158/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9453 - loss: 0.1354\n",
      "Epoch 158: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.9401 - loss: 0.1411 - val_accuracy: 0.9677 - val_loss: 0.0994\n",
      "Epoch 159/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9453 - loss: 0.1502\n",
      "Epoch 159: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9382 - loss: 0.1529 - val_accuracy: 0.9758 - val_loss: 0.1008\n",
      "Epoch 160/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9062 - loss: 0.2290\n",
      "Epoch 160: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9255 - loss: 0.1910 - val_accuracy: 0.9677 - val_loss: 0.0984\n",
      "Epoch 161/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9297 - loss: 0.1902\n",
      "Epoch 161: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9329 - loss: 0.1742 - val_accuracy: 0.9758 - val_loss: 0.1011\n",
      "Epoch 162/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9297 - loss: 0.1803\n",
      "Epoch 162: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9240 - loss: 0.1794 - val_accuracy: 0.9677 - val_loss: 0.1042\n",
      "Epoch 163/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9219 - loss: 0.1670\n",
      "Epoch 163: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.9146 - loss: 0.1710 - val_accuracy: 0.9677 - val_loss: 0.1009\n",
      "Epoch 164/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9531 - loss: 0.1225\n",
      "Epoch 164: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.9518 - loss: 0.1493 - val_accuracy: 0.9758 - val_loss: 0.0983\n",
      "Epoch 165/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9453 - loss: 0.1429\n",
      "Epoch 165: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.9374 - loss: 0.1581 - val_accuracy: 0.9758 - val_loss: 0.0965\n",
      "Epoch 166/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9531 - loss: 0.1209\n",
      "Epoch 166: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9425 - loss: 0.1377 - val_accuracy: 0.9758 - val_loss: 0.0944\n",
      "Epoch 167/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8984 - loss: 0.2356\n",
      "Epoch 167: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.9138 - loss: 0.1919 - val_accuracy: 0.9758 - val_loss: 0.0932\n",
      "Epoch 168/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9219 - loss: 0.1607\n",
      "Epoch 168: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9300 - loss: 0.1646 - val_accuracy: 0.9839 - val_loss: 0.0924\n",
      "Epoch 169/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9062 - loss: 0.1783\n",
      "Epoch 169: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9265 - loss: 0.1587 - val_accuracy: 0.9839 - val_loss: 0.0912\n",
      "Epoch 170/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9297 - loss: 0.1534\n",
      "Epoch 170: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9403 - loss: 0.1459 - val_accuracy: 0.9758 - val_loss: 0.0899\n",
      "Epoch 171/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9766 - loss: 0.1165\n",
      "Epoch 171: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9549 - loss: 0.1347 - val_accuracy: 0.9839 - val_loss: 0.0893\n",
      "Epoch 172/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9297 - loss: 0.1695\n",
      "Epoch 172: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.9296 - loss: 0.1776 - val_accuracy: 0.9758 - val_loss: 0.0898\n",
      "Epoch 173/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9609 - loss: 0.1143\n",
      "Epoch 173: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9497 - loss: 0.1292 - val_accuracy: 0.9758 - val_loss: 0.0899\n",
      "Epoch 174/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.9375 - loss: 0.1744\n",
      "Epoch 174: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9296 - loss: 0.1613 - val_accuracy: 0.9758 - val_loss: 0.0898\n",
      "Epoch 175/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.9453 - loss: 0.1713\n",
      "Epoch 175: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9353 - loss: 0.1773 - val_accuracy: 0.9839 - val_loss: 0.0912\n",
      "Epoch 176/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9609 - loss: 0.1222\n",
      "Epoch 176: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9497 - loss: 0.1347 - val_accuracy: 0.9839 - val_loss: 0.0917\n",
      "Epoch 177/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9141 - loss: 0.1695\n",
      "Epoch 177: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9290 - loss: 0.1499 - val_accuracy: 0.9758 - val_loss: 0.0914\n",
      "Epoch 178/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9688 - loss: 0.1105\n",
      "Epoch 178: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9446 - loss: 0.1479 - val_accuracy: 0.9839 - val_loss: 0.0901\n",
      "Epoch 179/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.8984 - loss: 0.1971\n",
      "Epoch 179: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9315 - loss: 0.1486 - val_accuracy: 0.9839 - val_loss: 0.0875\n",
      "Epoch 180/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9531 - loss: 0.1294\n",
      "Epoch 180: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.9458 - loss: 0.1438 - val_accuracy: 0.9758 - val_loss: 0.0867\n",
      "Epoch 181/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9297 - loss: 0.1767\n",
      "Epoch 181: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.9349 - loss: 0.1564 - val_accuracy: 0.9839 - val_loss: 0.0867\n",
      "Epoch 182/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.9062 - loss: 0.1731\n",
      "Epoch 182: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.9214 - loss: 0.1591 - val_accuracy: 0.9839 - val_loss: 0.0863\n",
      "Epoch 183/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9609 - loss: 0.1078\n",
      "Epoch 183: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9598 - loss: 0.1127 - val_accuracy: 0.9839 - val_loss: 0.0847\n",
      "Epoch 184/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9219 - loss: 0.1783\n",
      "Epoch 184: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9364 - loss: 0.1539 - val_accuracy: 0.9839 - val_loss: 0.0823\n",
      "Epoch 185/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9531 - loss: 0.1852\n",
      "Epoch 185: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.9547 - loss: 0.1551 - val_accuracy: 0.9758 - val_loss: 0.0810\n",
      "Epoch 186/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.9453 - loss: 0.1280\n",
      "Epoch 186: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.9489 - loss: 0.1350 - val_accuracy: 0.9758 - val_loss: 0.0798\n",
      "Epoch 187/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9453 - loss: 0.1423\n",
      "Epoch 187: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.9403 - loss: 0.1423 - val_accuracy: 0.9839 - val_loss: 0.0802\n",
      "Epoch 188/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.9453 - loss: 0.1147\n",
      "Epoch 188: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9473 - loss: 0.1260 - val_accuracy: 0.9839 - val_loss: 0.0819\n",
      "Epoch 189/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9219 - loss: 0.1715\n",
      "Epoch 189: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.9370 - loss: 0.1515 - val_accuracy: 0.9839 - val_loss: 0.0847\n",
      "Epoch 190/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.9297 - loss: 0.1432\n",
      "Epoch 190: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9333 - loss: 0.1541 - val_accuracy: 0.9758 - val_loss: 0.0885\n",
      "Epoch 191/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9297 - loss: 0.1473\n",
      "Epoch 191: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9339 - loss: 0.1459 - val_accuracy: 0.9758 - val_loss: 0.0894\n",
      "Epoch 192/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9141 - loss: 0.1853\n",
      "Epoch 192: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.9280 - loss: 0.1612 - val_accuracy: 0.9758 - val_loss: 0.0887\n",
      "Epoch 193/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.9375 - loss: 0.1488\n",
      "Epoch 193: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9295 - loss: 0.1549 - val_accuracy: 0.9758 - val_loss: 0.0869\n",
      "Epoch 194/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9609 - loss: 0.1341\n",
      "Epoch 194: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9417 - loss: 0.1403 - val_accuracy: 0.9839 - val_loss: 0.0837\n",
      "Epoch 195/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9453 - loss: 0.1271\n",
      "Epoch 195: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9419 - loss: 0.1405 - val_accuracy: 0.9839 - val_loss: 0.0806\n",
      "Epoch 196/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9766 - loss: 0.0982\n",
      "Epoch 196: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9549 - loss: 0.1223 - val_accuracy: 0.9839 - val_loss: 0.0768\n",
      "Epoch 197/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9609 - loss: 0.1019\n",
      "Epoch 197: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9501 - loss: 0.1172 - val_accuracy: 0.9839 - val_loss: 0.0755\n",
      "Epoch 198/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9531 - loss: 0.1195\n",
      "Epoch 198: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9518 - loss: 0.1312 - val_accuracy: 0.9839 - val_loss: 0.0751\n",
      "Epoch 199/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9531 - loss: 0.1027\n",
      "Epoch 199: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.9489 - loss: 0.1184 - val_accuracy: 0.9839 - val_loss: 0.0760\n",
      "Epoch 200/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9609 - loss: 0.1185\n",
      "Epoch 200: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9549 - loss: 0.1307 - val_accuracy: 0.9839 - val_loss: 0.0783\n",
      "Epoch 201/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9453 - loss: 0.1350\n",
      "Epoch 201: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.9422 - loss: 0.1457 - val_accuracy: 0.9839 - val_loss: 0.0787\n",
      "Epoch 202/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9531 - loss: 0.1216\n",
      "Epoch 202: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9485 - loss: 0.1205 - val_accuracy: 0.9839 - val_loss: 0.0771\n",
      "Epoch 203/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9531 - loss: 0.1530\n",
      "Epoch 203: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9442 - loss: 0.1599 - val_accuracy: 0.9839 - val_loss: 0.0747\n",
      "Epoch 204/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9219 - loss: 0.1845\n",
      "Epoch 204: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.9344 - loss: 0.1551 - val_accuracy: 0.9839 - val_loss: 0.0761\n",
      "Epoch 205/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.9141 - loss: 0.1510\n",
      "Epoch 205: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.9257 - loss: 0.1496 - val_accuracy: 0.9839 - val_loss: 0.0764\n",
      "Epoch 206/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9609 - loss: 0.1011\n",
      "Epoch 206: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.9510 - loss: 0.1261 - val_accuracy: 0.9758 - val_loss: 0.0813\n",
      "Epoch 207/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.9375 - loss: 0.1535\n",
      "Epoch 207: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9440 - loss: 0.1429 - val_accuracy: 0.9758 - val_loss: 0.0831\n",
      "Epoch 208/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9219 - loss: 0.1768\n",
      "Epoch 208: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9341 - loss: 0.1447 - val_accuracy: 0.9758 - val_loss: 0.0818\n",
      "Epoch 209/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9766 - loss: 0.1060\n",
      "Epoch 209: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.9497 - loss: 0.1326 - val_accuracy: 0.9839 - val_loss: 0.0779\n",
      "Epoch 210/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 478ms/step - accuracy: 0.9531 - loss: 0.1189\n",
      "Epoch 210: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9452 - loss: 0.1378 - val_accuracy: 0.9839 - val_loss: 0.0738\n",
      "Epoch 211/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9219 - loss: 0.1980\n",
      "Epoch 211: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9311 - loss: 0.1702 - val_accuracy: 0.9839 - val_loss: 0.0737\n",
      "Epoch 212/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9531 - loss: 0.1135\n",
      "Epoch 212: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9492 - loss: 0.1282 - val_accuracy: 0.9839 - val_loss: 0.0738\n",
      "Epoch 213/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9531 - loss: 0.1219\n",
      "Epoch 213: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9504 - loss: 0.1291 - val_accuracy: 0.9839 - val_loss: 0.0733\n",
      "Epoch 214/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9609 - loss: 0.1223\n",
      "Epoch 214: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9514 - loss: 0.1246 - val_accuracy: 0.9839 - val_loss: 0.0736\n",
      "Epoch 215/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9453 - loss: 0.1386\n",
      "Epoch 215: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9456 - loss: 0.1314 - val_accuracy: 0.9839 - val_loss: 0.0721\n",
      "Epoch 216/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9453 - loss: 0.1384\n",
      "Epoch 216: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9395 - loss: 0.1502 - val_accuracy: 0.9839 - val_loss: 0.0708\n",
      "Epoch 217/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9453 - loss: 0.1691\n",
      "Epoch 217: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.9349 - loss: 0.1636 - val_accuracy: 0.9839 - val_loss: 0.0703\n",
      "Epoch 218/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9297 - loss: 0.1476\n",
      "Epoch 218: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.9279 - loss: 0.1566 - val_accuracy: 0.9839 - val_loss: 0.0709\n",
      "Epoch 219/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9609 - loss: 0.1019\n",
      "Epoch 219: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.9518 - loss: 0.1279 - val_accuracy: 0.9839 - val_loss: 0.0707\n",
      "Epoch 220/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9766 - loss: 0.1103\n",
      "Epoch 220: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.9563 - loss: 0.1223 - val_accuracy: 0.9839 - val_loss: 0.0709\n",
      "Epoch 221/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.9297 - loss: 0.1284\n",
      "Epoch 221: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9416 - loss: 0.1247 - val_accuracy: 0.9839 - val_loss: 0.0722\n",
      "Epoch 222/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.9609 - loss: 0.1308\n",
      "Epoch 222: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.9498 - loss: 0.1363 - val_accuracy: 0.9839 - val_loss: 0.0719\n",
      "Epoch 223/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9531 - loss: 0.1096\n",
      "Epoch 223: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.9444 - loss: 0.1291 - val_accuracy: 0.9839 - val_loss: 0.0686\n",
      "Epoch 224/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.9453 - loss: 0.1168\n",
      "Epoch 224: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9409 - loss: 0.1321 - val_accuracy: 0.9839 - val_loss: 0.0648\n",
      "Epoch 225/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9688 - loss: 0.1314\n",
      "Epoch 225: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.9604 - loss: 0.1236 - val_accuracy: 0.9839 - val_loss: 0.0719\n",
      "Epoch 226/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9297 - loss: 0.1575\n",
      "Epoch 226: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.9370 - loss: 0.1472 - val_accuracy: 0.9758 - val_loss: 0.0761\n",
      "Epoch 227/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9375 - loss: 0.1279\n",
      "Epoch 227: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9446 - loss: 0.1330 - val_accuracy: 0.9758 - val_loss: 0.0769\n",
      "Epoch 228/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9219 - loss: 0.1994\n",
      "Epoch 228: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9393 - loss: 0.1592 - val_accuracy: 0.9919 - val_loss: 0.0734\n",
      "Epoch 229/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9297 - loss: 0.1512\n",
      "Epoch 229: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9380 - loss: 0.1396 - val_accuracy: 0.9919 - val_loss: 0.0694\n",
      "Epoch 230/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.9453 - loss: 0.1109\n",
      "Epoch 230: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9356 - loss: 0.1357 - val_accuracy: 0.9839 - val_loss: 0.0653\n",
      "Epoch 231/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9453 - loss: 0.1159\n",
      "Epoch 231: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.9399 - loss: 0.1318 - val_accuracy: 0.9839 - val_loss: 0.0652\n",
      "Epoch 232/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9219 - loss: 0.1767\n",
      "Epoch 232: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9253 - loss: 0.1756 - val_accuracy: 0.9839 - val_loss: 0.0676\n",
      "Epoch 233/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9453 - loss: 0.1271\n",
      "Epoch 233: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9432 - loss: 0.1357 - val_accuracy: 0.9839 - val_loss: 0.0694\n",
      "Epoch 234/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9531 - loss: 0.1239\n",
      "Epoch 234: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.9553 - loss: 0.1215 - val_accuracy: 0.9839 - val_loss: 0.0701\n",
      "Epoch 235/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9609 - loss: 0.1126\n",
      "Epoch 235: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9555 - loss: 0.1275 - val_accuracy: 0.9839 - val_loss: 0.0690\n",
      "Epoch 236/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9297 - loss: 0.1711\n",
      "Epoch 236: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.9403 - loss: 0.1536 - val_accuracy: 0.9839 - val_loss: 0.0668\n",
      "Epoch 237/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9688 - loss: 0.1347\n",
      "Epoch 237: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.9571 - loss: 0.1335 - val_accuracy: 0.9758 - val_loss: 0.0692\n",
      "Epoch 238/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.9453 - loss: 0.1184\n",
      "Epoch 238: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.9398 - loss: 0.1327 - val_accuracy: 0.9758 - val_loss: 0.0730\n",
      "Epoch 239/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 523ms/step - accuracy: 0.9297 - loss: 0.1482\n",
      "Epoch 239: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9420 - loss: 0.1412 - val_accuracy: 0.9758 - val_loss: 0.0712\n",
      "Epoch 240/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9375 - loss: 0.1331\n",
      "Epoch 240: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9380 - loss: 0.1419 - val_accuracy: 0.9758 - val_loss: 0.0711\n",
      "Epoch 241/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9531 - loss: 0.1261\n",
      "Epoch 241: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.9512 - loss: 0.1351 - val_accuracy: 0.9758 - val_loss: 0.0727\n",
      "Epoch 242/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9531 - loss: 0.1099\n",
      "Epoch 242: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.9504 - loss: 0.1207 - val_accuracy: 0.9758 - val_loss: 0.0725\n",
      "Epoch 243/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9297 - loss: 0.1630\n",
      "Epoch 243: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.9323 - loss: 0.1565 - val_accuracy: 0.9839 - val_loss: 0.0686\n",
      "Epoch 244/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9609 - loss: 0.1039\n",
      "Epoch 244: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9611 - loss: 0.1058 - val_accuracy: 0.9839 - val_loss: 0.0646\n",
      "Epoch 245/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 0.9844 - loss: 0.0896\n",
      "Epoch 245: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9613 - loss: 0.1111 - val_accuracy: 0.9758 - val_loss: 0.0627\n",
      "Epoch 246/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9297 - loss: 0.1708\n",
      "Epoch 246: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9343 - loss: 0.1492 - val_accuracy: 0.9839 - val_loss: 0.0610\n",
      "Epoch 247/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9453 - loss: 0.1349\n",
      "Epoch 247: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9459 - loss: 0.1309 - val_accuracy: 0.9839 - val_loss: 0.0613\n",
      "Epoch 248/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9531 - loss: 0.1254\n",
      "Epoch 248: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 274ms/step - accuracy: 0.9531 - loss: 0.1256 - val_accuracy: 0.9919 - val_loss: 0.0654\n",
      "Epoch 249/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.9531 - loss: 0.1319\n",
      "Epoch 249: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.9502 - loss: 0.1270 - val_accuracy: 0.9839 - val_loss: 0.0703\n",
      "Epoch 250/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9141 - loss: 0.1354\n",
      "Epoch 250: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.9247 - loss: 0.1285 - val_accuracy: 0.9839 - val_loss: 0.0720\n",
      "Epoch 251/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.9609 - loss: 0.0941\n",
      "Epoch 251: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.9514 - loss: 0.1064 - val_accuracy: 0.9839 - val_loss: 0.0684\n",
      "Epoch 252/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9141 - loss: 0.1615\n",
      "Epoch 252: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.9377 - loss: 0.1298 - val_accuracy: 0.9919 - val_loss: 0.0602\n",
      "Epoch 253/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9688 - loss: 0.1008\n",
      "Epoch 253: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.9607 - loss: 0.1122 - val_accuracy: 0.9839 - val_loss: 0.0581\n",
      "Epoch 254/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9609 - loss: 0.1008\n",
      "Epoch 254: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.9531 - loss: 0.1117 - val_accuracy: 0.9839 - val_loss: 0.0589\n",
      "Epoch 255/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - accuracy: 0.9453 - loss: 0.1833\n",
      "Epoch 255: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - accuracy: 0.9502 - loss: 0.1599 - val_accuracy: 0.9919 - val_loss: 0.0639\n",
      "Epoch 256/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.0558\n",
      "Epoch 256: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.9709 - loss: 0.1057 - val_accuracy: 0.9839 - val_loss: 0.0682\n",
      "Epoch 257/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9297 - loss: 0.1273\n",
      "Epoch 257: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.9480 - loss: 0.1173 - val_accuracy: 0.9839 - val_loss: 0.0687\n",
      "Epoch 258/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.9062 - loss: 0.1580\n",
      "Epoch 258: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.9278 - loss: 0.1383 - val_accuracy: 0.9839 - val_loss: 0.0664\n",
      "Epoch 259/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9141 - loss: 0.1575\n",
      "Epoch 259: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9294 - loss: 0.1526 - val_accuracy: 0.9919 - val_loss: 0.0642\n",
      "Epoch 260/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 329ms/step - accuracy: 0.9375 - loss: 0.1833\n",
      "Epoch 260: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.9359 - loss: 0.1663 - val_accuracy: 0.9839 - val_loss: 0.0636\n",
      "Epoch 261/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9453 - loss: 0.1535\n",
      "Epoch 261: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.9489 - loss: 0.1324 - val_accuracy: 0.9839 - val_loss: 0.0642\n",
      "Epoch 262/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.9375 - loss: 0.1419\n",
      "Epoch 262: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.9450 - loss: 0.1424 - val_accuracy: 0.9839 - val_loss: 0.0637\n",
      "Epoch 263/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9688 - loss: 0.1260\n",
      "Epoch 263: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9551 - loss: 0.1332 - val_accuracy: 0.9839 - val_loss: 0.0635\n",
      "Epoch 264/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9219 - loss: 0.1581\n",
      "Epoch 264: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9354 - loss: 0.1448 - val_accuracy: 0.9919 - val_loss: 0.0629\n",
      "Epoch 265/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9609 - loss: 0.1105\n",
      "Epoch 265: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9611 - loss: 0.1092 - val_accuracy: 0.9919 - val_loss: 0.0630\n",
      "Epoch 266/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9531 - loss: 0.1428\n",
      "Epoch 266: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9535 - loss: 0.1353 - val_accuracy: 0.9919 - val_loss: 0.0624\n",
      "Epoch 267/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9453 - loss: 0.1604\n",
      "Epoch 267: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.9473 - loss: 0.1497 - val_accuracy: 0.9919 - val_loss: 0.0613\n",
      "Epoch 268/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9453 - loss: 0.1094\n",
      "Epoch 268: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.9378 - loss: 0.1314 - val_accuracy: 0.9919 - val_loss: 0.0617\n",
      "Epoch 269/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9453 - loss: 0.1546\n",
      "Epoch 269: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9599 - loss: 0.1243 - val_accuracy: 0.9919 - val_loss: 0.0626\n",
      "Epoch 270/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9688 - loss: 0.0906\n",
      "Epoch 270: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9588 - loss: 0.1075 - val_accuracy: 0.9919 - val_loss: 0.0626\n",
      "Epoch 271/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9688 - loss: 0.0999\n",
      "Epoch 271: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9584 - loss: 0.1108 - val_accuracy: 0.9919 - val_loss: 0.0601\n",
      "Epoch 272/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9609 - loss: 0.0949\n",
      "Epoch 272: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9568 - loss: 0.1207 - val_accuracy: 0.9919 - val_loss: 0.0573\n",
      "Epoch 273/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9609 - loss: 0.1243\n",
      "Epoch 273: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9565 - loss: 0.1190 - val_accuracy: 0.9919 - val_loss: 0.0601\n",
      "Epoch 274/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9453 - loss: 0.1353\n",
      "Epoch 274: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9580 - loss: 0.1127 - val_accuracy: 0.9919 - val_loss: 0.0613\n",
      "Epoch 275/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9297 - loss: 0.1575\n",
      "Epoch 275: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9387 - loss: 0.1323 - val_accuracy: 0.9919 - val_loss: 0.0598\n",
      "Epoch 276/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.9609 - loss: 0.1096\n",
      "Epoch 276: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9492 - loss: 0.1221 - val_accuracy: 0.9839 - val_loss: 0.0590\n",
      "Epoch 277/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9531 - loss: 0.1133\n",
      "Epoch 277: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.9582 - loss: 0.1044 - val_accuracy: 0.9839 - val_loss: 0.0598\n",
      "Epoch 278/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9688 - loss: 0.0954\n",
      "Epoch 278: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.9617 - loss: 0.1022 - val_accuracy: 0.9839 - val_loss: 0.0607\n",
      "Epoch 279/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.9531 - loss: 0.1099\n",
      "Epoch 279: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.9545 - loss: 0.1031 - val_accuracy: 0.9839 - val_loss: 0.0597\n",
      "Epoch 280/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9219 - loss: 0.1589\n",
      "Epoch 280: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.9428 - loss: 0.1390 - val_accuracy: 0.9839 - val_loss: 0.0593\n",
      "Epoch 281/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.9453 - loss: 0.1362\n",
      "Epoch 281: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.9489 - loss: 0.1175 - val_accuracy: 0.9919 - val_loss: 0.0616\n",
      "Epoch 282/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 343ms/step - accuracy: 0.9531 - loss: 0.1134\n",
      "Epoch 282: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - accuracy: 0.9595 - loss: 0.1026 - val_accuracy: 0.9839 - val_loss: 0.0647\n",
      "Epoch 283/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.9141 - loss: 0.1658\n",
      "Epoch 283: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9298 - loss: 0.1434 - val_accuracy: 0.9919 - val_loss: 0.0611\n",
      "Epoch 284/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9531 - loss: 0.0908\n",
      "Epoch 284: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.9485 - loss: 0.1016 - val_accuracy: 0.9919 - val_loss: 0.0569\n",
      "Epoch 285/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9219 - loss: 0.1488\n",
      "Epoch 285: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.9377 - loss: 0.1317 - val_accuracy: 0.9919 - val_loss: 0.0566\n",
      "Epoch 286/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.9297 - loss: 0.1528\n",
      "Epoch 286: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.9537 - loss: 0.1176 - val_accuracy: 0.9919 - val_loss: 0.0585\n",
      "Epoch 287/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9766 - loss: 0.0911\n",
      "Epoch 287: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9744 - loss: 0.0961 - val_accuracy: 0.9919 - val_loss: 0.0576\n",
      "Epoch 288/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9219 - loss: 0.2446\n",
      "Epoch 288: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.9438 - loss: 0.1761 - val_accuracy: 0.9919 - val_loss: 0.0569\n",
      "Epoch 289/1000\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9590 - loss: 0.0898\n",
      "Epoch 289: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.9551 - loss: 0.1025 - val_accuracy: 0.9919 - val_loss: 0.0542\n",
      "Epoch 290/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.9609 - loss: 0.0961\n",
      "Epoch 290: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.9615 - loss: 0.0897 - val_accuracy: 0.9919 - val_loss: 0.0527\n",
      "Epoch 291/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9844 - loss: 0.0644\n",
      "Epoch 291: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9670 - loss: 0.0923 - val_accuracy: 0.9919 - val_loss: 0.0525\n",
      "Epoch 292/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 0.9062 - loss: 0.1725\n",
      "Epoch 292: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.9329 - loss: 0.1392 - val_accuracy: 0.9919 - val_loss: 0.0537\n",
      "Epoch 293/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9531 - loss: 0.1177\n",
      "Epoch 293: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.9578 - loss: 0.1109 - val_accuracy: 0.9919 - val_loss: 0.0562\n",
      "Epoch 294/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9531 - loss: 0.0971\n",
      "Epoch 294: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.9562 - loss: 0.0964 - val_accuracy: 0.9919 - val_loss: 0.0572\n",
      "Epoch 295/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9766 - loss: 0.0908\n",
      "Epoch 295: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.9623 - loss: 0.1103 - val_accuracy: 0.9919 - val_loss: 0.0553\n",
      "Epoch 296/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9609 - loss: 0.0961\n",
      "Epoch 296: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.9619 - loss: 0.1067 - val_accuracy: 0.9919 - val_loss: 0.0565\n",
      "Epoch 297/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.9688 - loss: 0.0849\n",
      "Epoch 297: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.9537 - loss: 0.1116 - val_accuracy: 0.9919 - val_loss: 0.0563\n",
      "Epoch 298/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.9609 - loss: 0.1023\n",
      "Epoch 298: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9398 - loss: 0.1263 - val_accuracy: 0.9919 - val_loss: 0.0552\n",
      "Epoch 299/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9844 - loss: 0.0727\n",
      "Epoch 299: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9683 - loss: 0.0945 - val_accuracy: 0.9919 - val_loss: 0.0522\n",
      "Epoch 300/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9531 - loss: 0.0959\n",
      "Epoch 300: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.9574 - loss: 0.1050 - val_accuracy: 0.9919 - val_loss: 0.0536\n",
      "Epoch 301/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9844 - loss: 0.0683\n",
      "Epoch 301: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.9577 - loss: 0.0966 - val_accuracy: 0.9919 - val_loss: 0.0555\n",
      "Epoch 302/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9609 - loss: 0.1297\n",
      "Epoch 302: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9615 - loss: 0.1180 - val_accuracy: 0.9919 - val_loss: 0.0555\n",
      "Epoch 303/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9297 - loss: 0.1111\n",
      "Epoch 303: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9504 - loss: 0.1120 - val_accuracy: 0.9919 - val_loss: 0.0565\n",
      "Epoch 304/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9531 - loss: 0.1232\n",
      "Epoch 304: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9526 - loss: 0.1085 - val_accuracy: 0.9919 - val_loss: 0.0565\n",
      "Epoch 305/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9609 - loss: 0.1148\n",
      "Epoch 305: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.9526 - loss: 0.1107 - val_accuracy: 0.9919 - val_loss: 0.0544\n",
      "Epoch 306/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9609 - loss: 0.1329\n",
      "Epoch 306: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.9489 - loss: 0.1352 - val_accuracy: 0.9839 - val_loss: 0.0543\n",
      "Epoch 307/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9531 - loss: 0.1014\n",
      "Epoch 307: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.9601 - loss: 0.0937 - val_accuracy: 0.9919 - val_loss: 0.0542\n",
      "Epoch 308/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9453 - loss: 0.1383\n",
      "Epoch 308: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.9496 - loss: 0.1313 - val_accuracy: 0.9839 - val_loss: 0.0584\n",
      "Epoch 309/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - accuracy: 0.9531 - loss: 0.1049\n",
      "Epoch 309: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9535 - loss: 0.1025 - val_accuracy: 0.9839 - val_loss: 0.0585\n",
      "Epoch 310/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9297 - loss: 0.2059\n",
      "Epoch 310: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.9420 - loss: 0.1627 - val_accuracy: 0.9919 - val_loss: 0.0559\n",
      "Epoch 311/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9688 - loss: 0.0901\n",
      "Epoch 311: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9584 - loss: 0.1048 - val_accuracy: 0.9919 - val_loss: 0.0540\n",
      "Epoch 312/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9375 - loss: 0.1439\n",
      "Epoch 312: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.9510 - loss: 0.1208 - val_accuracy: 0.9919 - val_loss: 0.0543\n",
      "Epoch 313/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9609 - loss: 0.0734\n",
      "Epoch 313: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.9545 - loss: 0.1010 - val_accuracy: 0.9919 - val_loss: 0.0548\n",
      "Epoch 314/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9219 - loss: 0.1452\n",
      "Epoch 314: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9374 - loss: 0.1226 - val_accuracy: 0.9919 - val_loss: 0.0569\n",
      "Epoch 315/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9688 - loss: 0.0904\n",
      "Epoch 315: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.9621 - loss: 0.1041 - val_accuracy: 0.9919 - val_loss: 0.0573\n",
      "Epoch 316/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9609 - loss: 0.1310\n",
      "Epoch 316: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.9662 - loss: 0.1092 - val_accuracy: 0.9919 - val_loss: 0.0569\n",
      "Epoch 317/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9609 - loss: 0.0743\n",
      "Epoch 317: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.9588 - loss: 0.0910 - val_accuracy: 0.9919 - val_loss: 0.0557\n",
      "Epoch 318/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9609 - loss: 0.0957\n",
      "Epoch 318: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.9537 - loss: 0.1038 - val_accuracy: 0.9919 - val_loss: 0.0550\n",
      "Epoch 319/1000\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 347ms/step - accuracy: 0.9922 - loss: 0.0430\n",
      "Epoch 319: saving model to model/fsl_words_classifier/fsl_words_classifier.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.9662 - loss: 0.0777 - val_accuracy: 0.9919 - val_loss: 0.0547\n",
      "Epoch 319: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x28a14c788f0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[cp_callback, es_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存したモデルのロード\n",
    "model = tf.keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step\n",
      "[3.2684797e-10 1.0000000e+00]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# 推論テスト\n",
    "predict_result = model.predict(np.array([X_test[0]]))\n",
    "print(np.squeeze(predict_result))\n",
    "print(np.argmax(np.squeeze(predict_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 混同行列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        33\n",
      "           1       1.00      0.99      0.99        91\n",
      "\n",
      "    accuracy                           0.99       124\n",
      "   macro avg       0.99      0.99      0.99       124\n",
      "weighted avg       0.99      0.99      0.99       124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred, report=True):\n",
    "    labels = sorted(list(set(y_true)))\n",
    "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    \n",
    "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
    " \n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
    "    ax.set_ylim(len(set(y_true)), 0)\n",
    "    plt.show()\n",
    "    \n",
    "    if report:\n",
    "        print('Classification Report')\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow-Lite用のモデルへ変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論専用のモデルとして保存\n",
    "model.save(model_save_path, include_optimizer=False)\n",
    "model = tf.keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_save_path = 'model/fsl_words_classifier/fsl_words_classifier.tflite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Dell\\AppData\\Local\\Temp\\tmpzkt7tekb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Dell\\AppData\\Local\\Temp\\tmpzkt7tekb\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\Dell\\AppData\\Local\\Temp\\tmpzkt7tekb'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 32), dtype=tf.float32, name='input_layer_2')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 2), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2792081642256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2792081643792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2792081644368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2792081644560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2792081645136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2792081642832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2792081645904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "✅ TFLite変換完了: model/fsl_words_classifier/fsl_words_classifier.tflite\n"
     ]
    }
   ],
   "source": [
    "# モデルを変換(量子化\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)  # converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_path)\n",
    "# ✅ TensorListエラー回避のための設定\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,   # 標準TFLite演算\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS      # TensorFlow演算も許可\n",
    "]\n",
    "converter._experimental_lower_tensor_list_ops = False\n",
    "\n",
    "# ✅ 量子化（オプション）\n",
    "# LSTMを含むモデルではINT8量子化は非対応なので、Dynamic Rangeを使う\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# モデルを変換\n",
    "tflite_quantized_model = converter.convert()\n",
    "\n",
    "# 保存\n",
    "with open(tflite_save_path, 'wb') as f:\n",
    "    f.write(tflite_quantized_model)\n",
    "\n",
    "print(\"✅ TFLite変換完了:\", tflite_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推論テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'serving_default_input_layer_2:0', 'index': 0, 'shape': array([ 1, 32], dtype=int32), 'shape_signature': array([-1, 32], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "# 入出力テンソルを取得\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(input_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 推論実施\n",
    "interpreter.invoke()\n",
    "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.3018893e-10 1.0000000e+00]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(np.squeeze(tflite_results))\n",
    "print(np.argmax(np.squeeze(tflite_results)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
